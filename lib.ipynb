{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper  # Whisper for speech-to-text conversion\n",
    "import sounddevice as sd  # Sounddevice to record audio from the microphone\n",
    "import numpy as np  # Importing NumPy to handle audio arrays\n",
    "import wave  # Wave module to save and process recorded audio\n",
    "from llama_cpp import Llama  # Importing a  LLaMA model for task processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening, Speak Now.\n",
      "Audio Saved\n"
     ]
    }
   ],
   "source": [
    "def record_aud(filename = \"record.wav\",duration = 5, samplerate = 16000):\n",
    "    print(\"Listening, Speak Now.\")\n",
    "    recording = sd.rec(int(samplerate*duration), samplerate = samplerate,channels = 1, dtype = np.int16)\n",
    "    sd.wait()\n",
    "\n",
    "    with wave.open(filename,\"wb\") as wf:\n",
    "        wf.setnchannels(1)  # Set mono audio\n",
    "        wf.setsampwidth(2)  # Set sample width (16-bit)\n",
    "        wf.setframerate(samplerate)  # Set frame rate (16,000 samples/sec)\n",
    "        wf.writeframes(recording.tobytes())  # Write raw audio data\n",
    "    \n",
    "    print(\"Audio Saved\")\n",
    "\n",
    "record_aud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio...\n",
      "\n",
      "Recognized Text: aur mother\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_audio(filename=\"record.wav\"):\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Reduce background noise\n",
    "    recognizer.energy_threshold = 300\n",
    "\n",
    "    with sr.AudioFile(filename) as source:\n",
    "        print(\"Processing audio...\")\n",
    "        audio = recognizer.record(source)  # Capture the whole audio\n",
    "\n",
    "    try:\n",
    "        # Transcribe with Google API\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"\\nRecognized Text:\", text)\n",
    "        return text\n",
    "    \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech recognition could not understand the audio.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"Could not request results from Google Speech Recognition service.\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transcribe_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_task(task_text):\n",
    "   \n",
    "    # Load the LLaMA model (Provide the correct model path)\n",
    "    llm = Llama(model_path=\"path_to_llama_model.gguf\")\n",
    "\n",
    "    # Create a prompt for LLaMA\n",
    "    prompt = f\"You are a task manager AI. A user said: '{task_text}'. Extract key tasks and suggest a schedule.\"\n",
    "    \n",
    "    # Process the input with LLaMA\n",
    "    response = llm(prompt)\n",
    "    \n",
    "    # Extract the AI-generated text response\n",
    "    ai_response = response['choices'][0]['text']\n",
    "\n",
    "    print(\"AI Response:\", ai_response)\n",
    "    return ai_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/NLP Run/venv/lib/python3.12/site-packages/llama_cpp/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import llama_cpp\n",
    "print(llama_cpp.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
